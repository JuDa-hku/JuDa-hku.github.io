---
layout: post
title: KMeans
categories:
- Machine Learning
tags:
- Algorithm
- scikit
---
* KMeans
---

## KMeans with plot
KMeans method is a very basic way to classify data, here I show a easy example to show how to use it to classify 2-d data with 3 labels.

{% highlight objc %}
import numpy as np
import pylab as pl
from matplotlib.colors import ListedColormap
##useful tool to have a colormap
from sklearn import neighbors

class1 = np.random.rand(30,2)
label1 = np.array([np.zeros(30)]).T
class1 = np.concatenate((class1, label1), axis=1)
class2 = np.random.rand(30,2)
label2 = np.array([np.ones(30)]).T
class2 = np.concatenate((class2, label2), axis=1)
class3 = np.random.rand(30,2)
label3 = np.array([np.ones(30)+1]).T
class3 = np.concatenate((class3, label3), axis=1)
class1[:,1] = class1[:,1] + 1
class2[:,0] = class2[:,0] + 0.5
dataset = np.concatenate((class1, class2, class3))
X = dataset[:, :-1]
y = dataset[:, -1]


cmap_data = ListedColormap([(1,0.6,0.6), (0.6, 1, 0.6), (0.6, 0.6, 1)])

h = 0.02 #step size in the mesh
n_neighbors = (1, 5, 10)
pl.figure(figsize = (8, 4)) 
for n_neighbor, i in zip(n_neighbors, range(1,4)):
    clf = neighbors.KNeighborsClassifier(n_neighbor)
    clf.fit(X, y)
    x_min, x_max = X[:,0].min()*0.9, X[:,0].max()*1.1
    y_min, y_max = X[:,1].min()*0.9, X[:,1].max()*1.1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
   
    ax = pl.subplot(1,3,i)
    ax.set_title('K = %i' %n_neighbor)
    pl.pcolormesh(xx, yy, Z, cmap= cmap_data)
    pl.xlim(x_min, x_max)
    pl.ylim(y_min, y_max)
    pl.xticks([])
    pl.yticks([])
    pl.scatter(class1[:,0],class1[:,1], c='r', marker = 'o')
    pl.scatter(class2[:,0],class2[:,1], c='g', marker = 'o')
    pl.scatter(class3[:,0],class3[:,1], c='b', marker = 'o')
    
pl.savefig('knn_plot.png')
{% endhighlight objc %}

The plot is given below
![knn_plot](/png/knn_plot.png?raw=true)
